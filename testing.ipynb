{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import openai\n",
    "import praw\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import tweepy\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "from datetime import datetime \n",
    "load_dotenv()\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "REDDIT_CLIENT_ID = os.getenv('REDDIT_CLIENT_ID')\n",
    "REDDIT_CLIENT_SECRET = os.getenv('REDDIT_CLIENT_SECRET')\n",
    "REDDIT_USER_AGENT = os.getenv('REDDIT_USER_AGENT')\n",
    "REDDIT_USERNAME = os.getenv('REDDIT_USERNAME')\n",
    "REDDIT_PASSWORD = os.getenv('REDDIT_PASSWORD')\n",
    "\n",
    "# OpenAI API key\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "# client = openai.Client()\n",
    "\n",
    "# Twitter API credentials\n",
    "TWITTER_CONSUMER_KEY = os.getenv('TWITTER_CONSUMER_KEY')\n",
    "TWITTER_CONSUMER_SECRET = os.getenv('TWITTER_CONSUMER_SECRET')\n",
    "TWITTER_ACCESS_TOKEN = os.getenv('TWITTER_ACCESS_TOKEN')\n",
    "TWITTER_ACCESS_SECRET = os.getenv('TWITTER_ACCESS_SECRET')\n",
    "\n",
    "# Social Searcher API key\n",
    "SOCIAL_SEARCHER_API_KEY = os.getenv('SOCIAL_SEARCHER_API_KEY')\n",
    "\n",
    "# Create Reddit API client (PRAW) - way to interact with Reddit API\n",
    "reddit = praw.Reddit(client_id=REDDIT_CLIENT_ID,\n",
    "                     client_secret=REDDIT_CLIENT_SECRET,\n",
    "                     user_agent=REDDIT_USER_AGENT,\n",
    "                     username=REDDIT_USERNAME,\n",
    "                     password=REDDIT_PASSWORD,\n",
    "                     ratelimit_seconds=5)\n",
    "    \n",
    "# Create Twitter API client\n",
    "auth = tweepy.OAuthHandler(TWITTER_CONSUMER_KEY, TWITTER_CONSUMER_SECRET)\n",
    "auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_SECRET)\n",
    "twitter_api = tweepy.API(auth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_name = \"Amplifire AI\"\n",
    "business_description = \"Generate more leads from social media across LinkedIn, Facebook, X/Twitter, Reddit, and Instagram! We automate finding customers, and our AI replies to frustrated users' posts with genuinely valuable replies to help them. Then, we subtly provide your business with a solution to their problems in a way that doesn't come across as spammy!\"\n",
    "business_website = \"https://amplifire-ai.vercel.app/\"\n",
    "business_location = \"\"\n",
    "business_industry = \"Artificial Intelligence\"\n",
    "business_tap = \"Startups and small businesses seeking AI-powered\"\n",
    "business_keywords = \"AI marketing automation, lead generation, AI business growth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_reddit_reply(post, business_name, business_description, website_link):\n",
    "    description = post.selftext[:5000]\n",
    "    response = openai.ChatCompletion.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": f\"You are a thoughtful and insightful Reddit user who provides genuine and valuable responses to posts. Your goal is to assist users by offering advice, insights, or solutions. And naturally mention our business, {business_name}, in a way that adds value to the conversation. Include our link, {website_link}, if it fits naturally, explaining briefly how it might help with their issue. Avoid being overly promotional or spammy. Maintain a neutral and helpful tone throughout your response.\"\n",
    "                },\n",
    "                \n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": f\"\"\"\n",
    "                        Please analyze the following Reddit post's title and description and craft a genuine and helpful reply that provides value to the user. \n",
    "                        Find a way to naturally recommend our business, if it is relevant and can be seamlessly integrated into your response. \n",
    "                        If you can't mention the business naturally, focus solely on providing valuable advice. Focus on speaking in a neutral tone and avoid using exclaimation marks. \n",
    "                        Please try to find a way to RECOMMEND our, in the reply naturally and preferably mention the, as well.\n",
    "                        when promiting the business ensure you have mentioned the name. if the website link is relevent then add that too.\n",
    "                        Everything after this point is information for you to use in your response. reply only with the generated comment and nothing else. \n",
    "                        make the english simple and smooth and in style of a comment\n",
    "                        Title: {post.title}\n",
    "                        Description: {description}\n",
    "                        Our Business Name: {business_name}\n",
    "                        Our Business Description: {business_description}\n",
    "                        Our Website Link: {website_link}\n",
    "                    \"\"\"\n",
    "                }\n",
    "            ],\n",
    "            max_tokens=300,\n",
    "            temperature=0.7\n",
    "        )\n",
    "    return response.choices[0].message.content.strip()\n",
    "\n",
    "def check_rate_limit(reddit):\n",
    "    limits = reddit.auth.limits\n",
    "    remaining = limits.get('remaining', None)\n",
    "    reset_timestamp = limits.get('reset_timestamp', None)\n",
    "    \n",
    "    if remaining is not None and remaining <= 1:\n",
    "        logging.warning(f\"Rate limit reached. Waiting until reset.\")\n",
    "        reset_in = reset_timestamp - time.time()\n",
    "        if reset_in > 0:\n",
    "            logging.info(f\"Waiting for {reset_in:.2f} seconds until rate limit resets.\")\n",
    "            time.sleep(reset_in)  # Wait until the rate limit resets\n",
    "    else:\n",
    "       print(f\"Remaining API requests: {remaining}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_reddit_leads(keyword, location, business_name, business_description, website_link):\n",
    "    logging.info(f\"Searching for keyword: {keyword}\")\n",
    "    # TODO: if already posted on specific post, don't post again. How can we keep track of this? For example if a user uses it one day and then again the next day, we don't want to post on the same post again.\n",
    "    if location:\n",
    "        logging.info(f\"Location provided: {location}\")\n",
    "        keyword = f\"{keyword} {location}\"\n",
    "\n",
    "    subreddit = reddit.subreddit(\"all\")\n",
    "    posts = {}\n",
    "    \n",
    "    # Load previously posted post IDs from a file to avoid duplicate posts\n",
    "    try:\n",
    "        with open('all_posts.json', 'r') as f:\n",
    "            all_posts = json.load(f)\n",
    "    except Exception as e:\n",
    "        all_posts = {}\n",
    "\n",
    "    # Set a limit for the number of new posts to comment on\n",
    "    max_new_posts = 5\n",
    "    new_posts_found = 0\n",
    "\n",
    "\n",
    "    # Search through posts, but only comment on new ones\n",
    "    for post in subreddit.search(keyword, limit=5):  # Increase the limit to search more posts\n",
    "        logging.info(f\"Processing post: {post.title}\")\n",
    "\n",
    "        # Skip if we've already posted in this exact post\n",
    "        if post.id in all_posts:\n",
    "            logging.info(f\"Already processed this post: {post.title}, skipping...\")\n",
    "            continue  # Skip to the next post so we don't waste AI credits\n",
    "\n",
    "        if post.archived:\n",
    "            logging.info(f\"Post is archived: {post.title}, skipping...\")\n",
    "            continue\n",
    "\n",
    "        # Create the comment  \n",
    "            \n",
    "        comment = generate_reddit_reply(post, business_name, business_description, website_link)\n",
    "\n",
    "        # Add the post ID to the list of all posts (before the try block)\n",
    "        logging.info(f\"Comment generated: {comment}\") # Log the comment that was generated\n",
    "\n",
    "        try:\n",
    "            # Post the comment\n",
    "            all_posts[post.id] = {\n",
    "                'id': post.id,\n",
    "                'description': post.title,\n",
    "                'url': post.url,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'comment': comment,\n",
    "                # \"comment_url\": f\"https://www.reddit.com{posted_comment.permalink}\"\n",
    "            }\n",
    "            posted_comment = post.reply(comment)\n",
    "            logging.info(f\"Comment posted successfully on post: {post.title}\")\n",
    "            logging.info(f\"Comment ID: {posted_comment.id}\")\n",
    "            logging.info(f\"Comment URL: https://www.reddit.com{posted_comment.permalink}\")\n",
    "\n",
    "            # Increment the count of new posts found\n",
    "            new_posts_found += 1\n",
    "\n",
    "            # If we've found enough new posts, stop searching\n",
    "            if new_posts_found >= max_new_posts:\n",
    "                logging.info(f\"Found {new_posts_found} new posts, stopping search.\")\n",
    "                break\n",
    "            all_posts[post.id] = {\n",
    "                'id': post.id,\n",
    "                'description': post.title,\n",
    "                'url': post.url,\n",
    "                'timestamp': datetime.now().isoformat(),\n",
    "                'comment': comment,\n",
    "                # \"comment_url\": f\"https://www.reddit.com{posted_comment.permalink}\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error posting comment on post: {post.title}\")\n",
    "            logging.error(f\"Error message: {str(e)}\")\n",
    "\n",
    "        \n",
    "\n",
    "        # Save the updated list of posted post IDs to a file TODO: Improve this to not write the posts that haven't been replied too because of rate limits... We might just have to do not automatic posts and just show the user the posts and let them decide which ones to post on.\n",
    "    with open('all_posts.json', 'w') as f: # by opening a file we overwrite the previous content\n",
    "        json.dump(all_posts, f, indent=4) # add the list of posted posts to the file\n",
    "\n",
    "        # Add a random delay between 30 and 60 seconds to avoid spam detection\n",
    "        # delay = random.randint(5, 10)\n",
    "        # logging.info(f\"Waiting for {delay} seconds before posting the next comment...\")\n",
    "        # time.sleep(delay)\n",
    "    \n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Error posting comment on post: How To Use AI In My Coaching Business\n",
      "ERROR:root:Error message: RATELIMIT: \"Looks like you've been doing that a lot. Take a break for 6 minutes before trying again.\" on field 'ratelimit'\n",
      "ERROR:root:Error posting comment on post: The Future of Generative AI in Manufacturing: AI Innovations, Real-Life Examples and Challenges\n",
      "ERROR:root:Error message: RATELIMIT: \"Looks like you've been doing that a lot. Take a break for 6 minutes before trying again.\" on field 'ratelimit'\n",
      "ERROR:root:Error posting comment on post: AI-Amplified Click Lead Generation using GO - AI: The Key to Exponential Growth\n",
      "ERROR:root:Error message: RATELIMIT: \"Looks like you've been doing that a lot. Take a break for 6 minutes before trying again.\" on field 'ratelimit'\n",
      "ERROR:root:Error posting comment on post: MailerMonster – Review of the World’s First Gemini Ultra Autoresponder: Google’s Cutting-Edge AI for Generating Endless Content and Emails to Unlimited Subscribers, All Free of Monthly Fees!\n",
      "ERROR:root:Error message: RATELIMIT: \"Looks like you've been doing that a lot. Take a break for 6 minutes before trying again.\" on field 'ratelimit'\n",
      "ERROR:root:Error posting comment on post: BlogNinja Review: Discover an Automated AI Blog Creator that Delivers 100,000+ SEO-Optimized Posts, Facilitating Quick Profits via Affiliate Offers, AdSense, or Flippa for a Low One-Time Investment.\n",
      "ERROR:root:Error message: RATELIMIT: \"Looks like you've been doing that a lot. Take a break for 6 minutes before trying again.\" on field 'ratelimit'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fetch_reddit_leads(business_keywords, business_location, business_name, business_description, business_website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1edkg15\n"
     ]
    },
    {
     "ename": "RedditAPIException",
     "evalue": "RATELIMIT: \"Looks like you've been doing that a lot. Take a break for 7 minutes before trying again.\" on field 'ratelimit'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRedditAPIException\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m subreddit\u001b[38;5;241m.\u001b[39msearch(business_keywords, limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(post\u001b[38;5;241m.\u001b[39mid)\n\u001b[0;32m----> 4\u001b[0m     reply \u001b[38;5;241m=\u001b[39m \u001b[43mpost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124murl: \u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.reddit.com\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreply\u001b[38;5;241m.\u001b[39mpermalink\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/temp/lib/python3.10/site-packages/praw/models/reddit/mixins/replyable.py:43\u001b[0m, in \u001b[0;36mReplyableMixin.reply\u001b[0;34m(self, body)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Reply to the object.\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m:param body: The Markdown formatted content for a comment.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     40\u001b[0m \n\u001b[1;32m     41\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     42\u001b[0m data \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m: body, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthing_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfullname}\n\u001b[0;32m---> 43\u001b[0m comments \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reddit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAPI_PATH\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcomment\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m comments[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/temp/lib/python3.10/site-packages/praw/util/deprecate_args.py:43\u001b[0m, in \u001b[0;36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m     arg_string \u001b[38;5;241m=\u001b[39m _generate_arg_string(_old_args[: \u001b[38;5;28mlen\u001b[39m(args)])\n\u001b[1;32m     37\u001b[0m     warn(\n\u001b[1;32m     38\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPositional arguments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m will no longer be\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m supported in PRAW 8.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCall this function with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     40\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m     41\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m     42\u001b[0m     )\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_old_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/temp/lib/python3.10/site-packages/praw/reddit.py:858\u001b[0m, in \u001b[0;36mReddit.post\u001b[0;34m(self, path, data, files, json, params)\u001b[0m\n\u001b[1;32m    856\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRate limit hit, sleeping for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseconds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msecond_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    857\u001b[0m         time\u001b[38;5;241m.\u001b[39msleep(seconds)\n\u001b[0;32m--> 858\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m last_exception\n",
      "File \u001b[0;32m~/miniconda3/envs/temp/lib/python3.10/site-packages/praw/reddit.py:842\u001b[0m, in \u001b[0;36mReddit.post\u001b[0;34m(self, path, data, files, json, params)\u001b[0m\n\u001b[1;32m    840\u001b[0m attempts \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    841\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 842\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_objectify_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    844\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    845\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    846\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    847\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    848\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    849\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m RedditAPIException \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m    851\u001b[0m     last_exception \u001b[38;5;241m=\u001b[39m exception\n",
      "File \u001b[0;32m~/miniconda3/envs/temp/lib/python3.10/site-packages/praw/reddit.py:516\u001b[0m, in \u001b[0;36mReddit._objectify_request\u001b[0;34m(self, data, files, json, method, params, path)\u001b[0m\n\u001b[1;32m    491\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_objectify_request\u001b[39m(\n\u001b[1;32m    492\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    493\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    499\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    500\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    501\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run a request through the ``Objector``.\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \n\u001b[1;32m    503\u001b[0m \u001b[38;5;124;03m    :param data: Dictionary, bytes, or file-like object to send in the body of the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    514\u001b[0m \n\u001b[1;32m    515\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_objector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobjectify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfiles\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m            \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/temp/lib/python3.10/site-packages/praw/objector.py:232\u001b[0m, in \u001b[0;36mObjector.objectify\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    230\u001b[0m     errors \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjson\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    231\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(errors) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 232\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m RedditAPIException(errors)\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;129;01mand\u001b[39;00m (\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshortName\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m data \u001b[38;5;129;01mor\u001b[39;00m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmenu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmoderators\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    235\u001b[0m ):\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# This is a widget\u001b[39;00m\n\u001b[1;32m    237\u001b[0m     parser \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparsers\u001b[38;5;241m.\u001b[39mget(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparsers[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwidget\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mRedditAPIException\u001b[0m: RATELIMIT: \"Looks like you've been doing that a lot. Take a break for 7 minutes before trying again.\" on field 'ratelimit'"
     ]
    }
   ],
   "source": [
    "subreddit = reddit.subreddit(\"all\")\n",
    "for post in subreddit.search(business_keywords, limit=10):\n",
    "    print(post.id)\n",
    "    reply = post.reply(\"test\")\n",
    "    print(\"url: \",f\"https://www.reddit.com{reply.permalink}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining API requests: 994.0\n"
     ]
    }
   ],
   "source": [
    "check_rate_limit(reddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
